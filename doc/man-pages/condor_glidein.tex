\begin{ManPage}{\label{man-condor-glidein}\Condor{glidein}}{1}
{add a remote grid resource to a local HTCondor pool}
\Synopsis
\SynProg{\Condor{glidein}}
\oOpt{-help}

\SynProg{\Condor{glidein}}
\oOptArg{-admin}{address}
\oOpt{-anybody}
\oOptArg{-archdir}{dir}
\oOptArg{-basedir}{basedir}
\oOptArg{-count}{CPU count}
\oOpt{<Execute Task Options>}
\oOpt{<Generate File Options>}
\oOptArg{-gsi\_daemon\_name}{cert\_name}
\oOptArg{-idletime}{minutes}
\oOptArg{-install\_gsi\_trusted\_ca\_dir}{path}
\oOptArg{-install\_gsi\_gridmap}{file}
\oOptArg{-localdir}{dir}
\oOptArg{-memory}{MBytes}
\oOptArg{-project}{name}
\oOptArg{-queue}{name}
\oOptArg{-runtime}{minutes}
\oOpt{-runonly}
\oOpt{<Set Up Task Options>}
\oOptArg{-suffix}{suffix}
\oOptArg{-slots}{slot count}
\Arg{<contact argument>}

\index{HTCondor commands!condor\_glidein}
\index{condor\_glidein command}

\Description

\Condor{glidein} allows the temporary addition of a grid resource to
a local HTCondor pool.
The addition is accomplished by installing and executing some of the HTCondor
daemons on the remote grid resource,
such that it reports in as part of the local HTCondor pool.
\Condor{glidein} accomplishes two separate tasks: set up and execution.
These separated tasks allow flexibility, 
in that the user may use \Condor{glidein} to do only one
of the tasks or both, 
in addition to customizing the tasks.

The set up task generates a script that may be used
to start the HTCondor daemons during the execution task,
places this script on the remote grid resource,
composes and installs a configuration file,
and it installs the \Condor{master}, \Condor{startd}
and \Condor{starter} daemons on the grid resource.

The execution task runs the script generated by
the set up task.
The goal of the script is to invoke the \Condor{master} daemon.
The HTCondor job \Prog{glidein\_startup} appears in the queue of the local
HTCondor pool for each invocation of  \Condor{glidein}.
To remove the grid resource from the local HTCondor pool,
use \Condor{rm} to remove the \Prog{glidein\_startup} job.

The HTCondor jobs to do both the set up and execute tasks
utilize
HTCondor-G and Globus gt2 protocols to communicate with the remote resource.
Therefore,
an X.509 certificate (proxy) is required
for the user running \Condor{glidein}.

Specify the remote grid machine with the command line
argument \Arg{<contact argument>}.
\Arg{<contact argument>} takes one of 4 forms:
\begin{enumerate}
  \item \Arg{hostname} 
  \item \Arg{Globus contact string} 
  \item \Arg{hostname/jobmanager-<schedulername>} 
  \item \OptArg{-contactfile}{filename} 
\end{enumerate}
The argument \OptArg{-contactfile}{filename} specifies the full
path and file name of a file that contains Globus contact strings.
Each of the resources given by a Globus contact string 
is added to the local HTCondor pool.

The set up task of \Condor{glidein}
copies the binaries for the correct platform from a central server.
To obtain access to the server,
or to set up your own server, follow
instructions on the Glidein Server Setup page,
at \URL{http://www.cs.wisc.edu/condor/glidein}.
Set up need only be done once per site, as the installation
is never removed.

By default, all files installed on the remote grid resource are placed in
the directory
\File{\MacroUNI{HOME}/Condor\_glidein}.
\MacroUNI{HOME} is evaluated and defined 
on the remote machine using a grid map.
This directory must be in a shared file system accessible
by all machines that will run the HTCondor daemons.
By default, the daemon's log files will also be written in this 
directory.
Change this directory with the \Opt{-localdir} option to make
HTCondor daemons write to local scratch space on the execution machine.
For debugging initial problems, it may be convenient to have the log
files in the more accessible default directory.
If using the default directory, 
occasionally clean up old log and execute directories
to avoid running out of space.

\Examples

To have
10 grid resources running PBS at a grid site with a
gatekeeper named gatekeeper.site.edu join the local HTCondor pool:
\begin{verbatim}
% condor_glidein -count 10 gatekeeper.site.edu/jobmanager-pbs
\end{verbatim}

If you try something like the above and \Condor{glidein} is not able to
automatically determine everything it needs to know about the remote site,
it will ask you to provide more information.  A typical result of this
process is something like the following command:
\begin{verbatim}
% condor_glidein \
    -count 10 \
    -arch 6.6.7-i686-pc-Linux-2.4 \
    -setup_jobmanager jobmanager-fork \
    gatekeeper.site.edu/jobmanager-pbs
\end{verbatim}

The HTCondor jobs that do the set up and execute tasks
will appear in the queue for the local HTCondor pool.
As a result of a successful glidein,
use \Condor{status} to see that the remote grid resources
are part of the local HTCondor pool.

A list of common problems and solutions is presented in this
manual page.

% Karen's LaTeX yuck to make separate sections for options
\subsection*{Generate File Options}
\begin{description}
  \OptItem{\Opt{-genconfig}}{
    Create a local copy of the configuration file that may be used
    on the remote resource.
    The file is named \File{glidein\_condor\_config.<suffix>}.
    The string defined by \Sinful{suffix} defaults to the process
    id (PID) of the \Condor{glidein} process or is defined with
    the \Opt{-suffix} command line option.
    The configuration file may be edited for later use with
    the \Opt{-useconfig} option.  }
  \OptItem{\Opt{-genstartup}}{
    Create a local copy of the script used
    on the remote resource to invoke the \Condor{master}.
    The file is named \File{glidein\_startup.<suffix>}.
    The string defined by \Sinful{suffix} defaults to the process
    id (PID) of the \Condor{glidein} process or is defined with
    the \Opt{-suffix} command line option.
    The file may be edited for later use with the
    \Opt{-usestartup} option.  }
    \OptItem{\Opt{-gensubmit}}{Generate submit description files,
    but do not submit.
    The submit description file for the set up task is
    named \File{glidein\_setup.submit.<suffix>}.
    The submit description file for the execute task is
    named \File{glidein\_run.submit.<suffix>}.
    The string defined by \Sinful{suffix} defaults to the process
    id (PID) of the \Condor{glidein} process or is defined with
    the \Opt{-suffix} command line option.  }
%The string \Prog{<XXX>} is either the process id (PID)
%of the \Condor{glidein} process
%or a string defined by the \Opt{-suffix} command line option.
\end{description}

\subsection*{Set Up Task Options}
\begin{description}
  \OptItem{\Opt{-setuponly}}{
    Do only the set up task of \Condor{glidein}.
    This option cannot be run simultaneously with \Opt{-runonly}. }
  \OptItem{\Opt{-setup\_here}}{
    Do the set up task on the local machine,
    instead of at a remote grid resource.
    This may be used, for example,
    to do the set up task of \Condor{glidein} in an AFS area that is read-only
    from the remote grid resource. }
  \OptItem{\Opt{-forcesetup}}{ 
    During the set up task, force the copying of files,
    even if this overwrites existing files.
    Use this to push out changes to the configuration.} 
  \OptItem{\OptArg{-useconfig}{config\_file}}{
    The set up task copies the specified configuration file,
    rather than generating one.  }
  \OptItem{\OptArg{-usestartup}{startup\_file}}{
    The set up task copies the specified startup script,
    rather than generating one.  }
  \OptItem{\OptArg{-setup\_jobmanager}{jobmanagername}}{
    Identifies the jobmanager on the remote grid resource
    to receive the files during the set up task.  If a
    reasonable default can be discovered through MDS, this is optional.
    \Arg{jobmanagername} is a string representing any gt2
    name for the job manager.  The correct string in most cases
    will be \Arg{jobmanager-fork}.
    Other common strings may be \Arg{jobmanager}, \Arg{jobmanager-condor},
    \Arg{jobmanager-pbs}, and \Arg{jobmanager-lsf}. }
\end{description}

\subsection*{Execute Task Options}
\begin{description}
  \OptItem{\Opt{-runonly}}{
    Starts execution of the HTCondor daemons on the grid
    resource.  If any of the necessary files or executables are missing,
    \Condor{glidein} exits with an error code.
    This option cannot be run simultaneously with \Opt{-setuponly}. }
  \OptItem{\Opt{-run\_here}}{
    Runs \Condor{master} directly rather than submitting an HTCondor job
    that causes the remote execution.
    To instead generate a script that
    does this, use \Opt{-run\_here} in combination with
    \Opt{-gensubmit}.  This may be useful for running HTCondor daemons on
    resources that are not directly accessible by HTCondor.}
\end{description}

\begin{Options}
    \OptItem{\Opt{-help}}{Display brief usage information and exit.}
    \OptItem{\OptArg{-basedir}{basedir}}{
	Specifies the base directory on the remote grid resource
	used for placing files.
	The default directory is \File{\MacroUNI{HOME}/Condor\_glidein}
	on the grid resource.
	}
    \OptItem{\OptArg{-archdir}{dir}}{
	Specifies the directory on the remote grid resource for placement
	of the HTCondor executables. 
	The default value for \OptArg{-archdir}
	is based upon version information on the grid resource.
	It is of the form
	\File{\Sinful{basedir}/\Sinful{condor-version}-\Sinful{Globus canonicalsystemname}}. 
	An example of the directory
	(without the base directory)
	for HTCondor version 7.6.0
	running on a 64-bit Intel processor with RHEL 3 is
	\File{7.6.0-x86\_64-pc-Linux-2.4-glibc2.3} . }
    \OptItem{\OptArg{-localdir}{dir}}{
	Specifies the directory on the remote grid resource
	in which to create log and execution subdirectories needed by HTCondor.
	If limited disk quota in the home or base directory
	on the grid resource is a problem,
	set \Opt{-localdir} to a large temporary space,
	such as \File{/tmp} or \File{/scratch}.  If the batch system
        requires invocation of HTCondor daemons in a temporary scratch directory,
        '.' may be used for the definition of the \Opt{-localdir} option.
	}
    \OptItem{\OptArg{-arch}{architecture}}{
        Identifies the platform of the required tarball
	containing the correct HTCondor daemon executables to download
	and install.
	If a reasonable default can be discovered through MDS, this is
	optional.  A list of possible values may be found at
	\URL{http://www.cs.wisc.edu/condor/glidein/binaries}.
	The architecture
        name is the same as the tarball name without the suffix
	\File{tar.gz}.  An example is 6.6.5-i686-pc-Linux-2.4 . }
    \OptItem{\OptArg{-queue}{name}}{
	The argument \Arg{name} is a string used at the
	grid resource to identify a job queue.  }
    \OptItem{\OptArg{-project}{name}}{
	The argument \Arg{name} is a string used at the
	grid resource to identify a project name.  }
    \OptItem{\OptArg{-memory}{MBytes}}{
	The maximum memory size in Megabytes to request from the grid resource.
	}
    \OptItem{\OptArg{-count}{CPU count}}{
	The number of CPUs requested to join the local pool.
	The default is 1. }
    \OptItem{\OptArg{-slots}{slot count}}{
        For machines with multiple CPUs, the CPUs maybe divided
	up into slots. \Arg{slot count} is the number
	of slots that results.
	By default, HTCondor divides multiple-CPU resources such that
	each CPU is a slot, each with an equal share of RAM,
	disk, and swap space.
	This option configures the number of slots, so that
	multi-threaded jobs can run in a slot with multiple
	CPUs.
	For example, if 4 CPUs are requested and 
	\Opt{-slots} is not specified, HTCondor will
	divide the request up into 4 slots with 1 CPU each.
	However, if \OptArg{-slots}{2} is specified,
	HTCondor will divide the request up into 2 slots with
	2 CPUs each, and if \OptArg{-slots}{1} is
	specified, HTCondor will put all 4 CPUs into one slot. }
    \OptItem{\OptArg{-idletime}{minutes}}{
	The amount of time that a remote grid resource 
	will remain idle state, before the daemons shut down.
	A value of 0 (zero) means that the daemons never shut
	down due to remaining in the idle state.
	In this case,
	the \Opt{-runtime} option defines when the daemons shut down.
	The default value is 20 minutes.  }
    \OptItem{\OptArg{-runtime}{minutes}}{
	The maximum amount of time the HTCondor daemons on
	the remote grid resource
	will run before shutting themselves down. This option is useful
	for resources with enforced maximum run times. Setting
	\Opt{-runtime} to be a few minutes shorter than the enforced
	limit gives the daemons time to perform a graceful shut down.  }
    \OptItem{\Arg{-anybody}}{
	Sets the HTCondor \Expr{START} expression for the added
	remote grid resource to \Expr{True}.
	This permits any user's job which can run on
	the added remote grid resource to run.
	Without this option, only jobs owned by the user executing
	\Condor{glidein} can execute on the remote grid resource. WARNING:
	Using this option may violate the usage policies of many
	institutions.
	}
    \OptItem{\OptArg{-admin}{address}}{
	Where to send e-mail with problems.
	The default is the login of the user running
	\Condor{glidein} at UID domain of the local HTCondor pool.  }
    \OptItem{\OptArg{-suffix}{X}}{
        Suffix to use when generating files.  Default is process id. }
    \OptItem{\OptArg{-gsi\_daemon\_name}{cert\_name}}{
        Includes and enables GSI authentication in the 
        configuration for the remote grid resource.
	The argument is the GSI
        certificate name that the daemons will use to authenticate
        themselves.  }
    \OptItem{\OptArg{-install\_gsi\_trusted\_ca\_dir}{path}}{
        The argument identifies the directory
        containing the trusted CA certificates that the
        daemons are to use 
	(for example, \File{/etc/grid-security/certificates}).
	The contents of this directory will be installed at the remote
        site in the directory \File{\Sinful{basedir}/grid-security}. }
    \OptItem{\OptArg{-install\_gsi\_gridmap}{file}}{
        The argument is the file name
        of the GSI-specific X.509 map file that the daemons will use.
	The file will be installed at the remote site
        in \File{\Sinful{basedir}/grid-security}.
	The file contains
        entries mapping certificates to user names.  At the
        very least, it must contain an entry for the certificate
        given by the command-line option \OptArg{-gsi\_daemon\_name}.
	If other HTCondor
        daemons use different certificates, then this file will
        also list any certificates that the daemons
        will encounter for 
	the \Condor{schedd}, \Condor{collector}, and \Condor{negotiator}.
	See section~\ref{sec:GSI-Authentication} for more information. }
\end{Options}

\ExitStatus

\Condor{glidein} will exit with a status value of 0 (zero) upon 
complete success,
or with non-zero values upon failure.
The status value will be 1 (one) if 
\Condor{glidein} encountered an error making a directory,
was unable to copy a tar file,
encountered an error in parsing the command line,
or was not able to gather required information.
The status value will be 2 (two) if 
there was an error in the remote set up.
The status value will be 3 (three) if 
there was an error in remote submission.
The status value will be -1 (negative one) if 
no resource was specified in the command line.

Common problems are listed below.  Many of these are best discovered by
looking in the \File{StartLog} log file on the remote grid resource.

\begin{description}

\item[WARNING: The file xxx is not writable by condor]
This error occurs when
\Condor{glidein} is run in a directory that does not have the proper
permissions for HTCondor to access files.  An AFS directory
does not give HTCondor the user's AFS ACLs.

\item[Glideins fail to run due to GLIBC errors] Check the list of
available glidein binaries
(\URL{http://www.cs.wisc.edu/condor/glidein/binaries}), and try 
specifying the architecture name that includes the correct glibc
version for the remote grid site.

\item[Glideins join pool but no jobs run on them] One common
cause of this problem is that the remote grid resources are in a different
file system domain, and the submitted HTCondor jobs 
have an implicit
requirement that they must run in the same file system domain.  
See
section~\ref{sec:file-transfer} for details on
using HTCondor's file transfer capabilities to solve this problem.
Another cause of this
problem is a communication failure.  For example, a firewall may be
preventing the \Condor{negotiator} or the \Condor{schedd} daemons
from connecting to
the \Condor{startd} on the remote grid resource.
Although work is being done to remove
this requirement in the future, it is currently necessary to have full
bidirectional connectivity, at least over a restricted range of
ports.  See page~\pageref{param:HighPort} for more information on
configuring a port range.

\item[Glideins run but fail to join the pool] This may be caused by
the local pool's security settings or by a communication failure.  Check
that the security settings in the local pool's configuration file allow
write access to the remote grid resource.  To not modify
the security settings for the pool, run a separate pool
specifically for the remote grid resources,
and use flocking to balance jobs across
the two pools of resources.  If the log files
indicate a communication failure, then see the next item.

\item[The startd cannot connect to the collector] This may be caused
by several things.  One is a firewall.  Another is when the compute
nodes do not have even outgoing network access.  Configuration
to work without full network access to and from the compute nodes is
still in the experimental stages, so for now, the short answer is that
you must at least have a range of open (bidirectional) ports and set
up the configuration file as described on
page~\pageref{param:HighPort}.  Use the option \Opt{-genconfig},
edit the generated configuration file,
and then do the glidein execute task with the option \Opt{-useconfig}.)

Another possible cause of connectivity problems may be the use of UDP by
the \Condor{startd} to register itself with the \Condor{collector}.
Force it to use TCP as described on
page~\pageref{param:UpdateCollectorWithTcp}.

Yet another possible cause of connectivity problems is when the 
remote grid resources
have more than one network interface, and the default one chosen
by HTCondor is not the correct one.  One way to fix this is to modify
the glidein startup script using the \Opt{-genstartup} and \Opt{-usestartup}
options.
The script needs to determine the IP address associated with
the correct network interface, and assign this to the environment
variable \MacroNI{\_condor\_NETWORK\_INTERFACE}.

\item[NFS file locking problems]  If the \Opt{-localdir} option
uses files
on NFS (not recommended, but sometimes convenient
for testing), the HTCondor daemons may have trouble manipulating file
locks.  Try inserting the following into the configuration file:

\begin{verbatim}
IGNORE_NFS_LOCK_ERRORS = True
\end{verbatim}

\end{description}

\end{ManPage}
